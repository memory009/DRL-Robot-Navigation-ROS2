#!/usr/bin/env python3
"""
æ‰¹é‡å¯è¾¾æ€§éªŒè¯è„šæœ¬
åœ¨æœåŠ¡å™¨ï¼ˆæ—  Gazeboï¼‰è¿è¡Œï¼ŒåŠ è½½ä¿å­˜çš„è½¨è¿¹å¹¶æ‰¹é‡è®¡ç®—å¯è¾¾é›†
è¾“å…¥ï¼šassets/trajectories.pkl
è¾“å‡ºï¼šassets/reachability_results.json
"""

import sys
from pathlib import Path
import numpy as np
import torch
import pickle
import json
from tqdm import tqdm
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from TD3.TD3 import TD3
from verification.polar_verifier import verify_safety


def load_trajectories(pkl_path=None):
    """åŠ è½½ä¿å­˜çš„è½¨è¿¹"""
    if pkl_path is None:
        pkl_path = Path(__file__).parent.parent / "assets" / "trajectories.pkl"
    
    if not pkl_path.exists():
        raise FileNotFoundError(
            f"è½¨è¿¹æ–‡ä»¶ä¸å­˜åœ¨: {pkl_path}\n"
            f"è¯·å…ˆåœ¨æœ¬åœ°è¿è¡Œ collect_trajectories.py"
        )
    
    with open(pkl_path, 'rb') as f:
        trajectories = pickle.load(f)
    
    # è¿‡æ»¤æ‰å¤±è´¥çš„è½¨è¿¹
    valid_trajectories = [t for t in trajectories if t is not None]
    
    return valid_trajectories


def verify_single_trajectory(
    agent,
    trajectory_data,
    observation_error=0.01,
    sample_interval=10,
    verbose=False
):
    """
    éªŒè¯å•ä¸ªè½¨è¿¹çš„å¯è¾¾é›†
    
    Returns:
        trajectory_results: dict
    """
    states = trajectory_data['states']
    sampled_states = states[::sample_interval]
    
    results = []
    safe_count = 0
    
    for i, state in enumerate(sampled_states):
        step_idx = i * sample_interval
        
        # è®¡ç®—å¯è¾¾é›†
        is_safe, action_ranges = verify_safety(
            agent,
            state,
            observation_error=observation_error,
            bern_order=1,
            error_steps=4000,
        )
        
        # è®¡ç®—ç¡®å®šæ€§åŠ¨ä½œ
        det_action = agent.get_action(state, add_noise=False)
        
        width_v = action_ranges[0][1] - action_ranges[0][0]
        width_omega = action_ranges[1][1] - action_ranges[1][0]
        
        if is_safe:
            safe_count += 1
        
        result = {
            'step': step_idx,
            'det_action': det_action.tolist(),
            'action_ranges': action_ranges,
            'is_safe': is_safe,
            'width_v': float(width_v),
            'width_omega': float(width_omega),
            'min_laser': float(np.min(state[:20])),
            'distance': float(state[20]),
        }
        results.append(result)
    
    # ç»Ÿè®¡
    n_samples = len(sampled_states)
    trajectory_summary = {
        'n_samples': n_samples,
        'safe_count': safe_count,
        'safety_rate': safe_count / n_samples if n_samples > 0 else 0,
        'collision': trajectory_data['collision'],
        'goal_reached': trajectory_data['goal_reached'],
        'steps': trajectory_data['steps'],
        'total_reward': float(trajectory_data['total_reward']),
        'results': results,
    }
    
    return trajectory_summary


def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡éªŒè¯æ‰€æœ‰è½¨è¿¹"""
    print("\n" + "="*70)
    print("æ‰¹é‡å¯è¾¾æ€§éªŒè¯å·¥å…·")
    print("="*70)
    
    # ===== 1. åŠ è½½æ¨¡å‹ =====
    print("\n[1/3] åŠ è½½æ¨¡å‹...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    agent = TD3(
        state_dim=25,
        action_dim=2,
        max_action=1.0,
        device=device,
        load_model=True,
        model_name="TD3",
        load_directory=Path("models/TD3/Nov17_06-22-08_archived"),
    )
    print(f"  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {device})")
    
    # ===== 2. åŠ è½½è½¨è¿¹ =====
    print("\n[2/3] åŠ è½½ä¿å­˜çš„è½¨è¿¹...")
    trajectories = load_trajectories()
    n_trajectories = len(trajectories)
    print(f"  âœ… åŠ è½½ {n_trajectories} æ¡è½¨è¿¹")
    
    # ç»Ÿè®¡è½¨è¿¹ä¿¡æ¯
    total_states = sum(t['steps'] for t in trajectories)
    print(f"  æ€»çŠ¶æ€æ•°: {total_states}")
    print(f"  å¹³å‡é•¿åº¦: {total_states/n_trajectories:.1f} æ­¥/è½¨è¿¹")
    
    # ===== 3. æ‰¹é‡éªŒè¯ =====
    print(f"\n[3/3] æ‰¹é‡éªŒè¯å¯è¾¾é›†...")
    print(f"  è§‚æµ‹è¯¯å·®: Â±0.01")
    print(f"  é‡‡æ ·é—´éš”: æ¯10æ­¥")
    print(f"  Bernsteiné˜¶æ•°: 1")
    print()
    
    all_results = []
    start_time = time.time()
    
    for i, trajectory_data in enumerate(tqdm(trajectories, desc="éªŒè¯è¿›åº¦")):
        try:
            trajectory_summary = verify_single_trajectory(
                agent,
                trajectory_data,
                observation_error=0.01,
                sample_interval=10,
                verbose=False
            )
            all_results.append(trajectory_summary)
            
        except Exception as e:
            print(f"\n  âŒ è½¨è¿¹ {i+1} éªŒè¯å¤±è´¥: {e}")
            all_results.append(None)
    
    elapsed_time = time.time() - start_time
    
    # ===== 4. æ±‡æ€»ç»Ÿè®¡ =====
    print("\n" + "="*70)
    print("éªŒè¯ç»Ÿè®¡:")
    print("="*70)
    
    valid_results = [r for r in all_results if r is not None]
    
    # 4.1 æ•´ä½“ç»Ÿè®¡
    total_samples = sum(r['n_samples'] for r in valid_results)
    total_safe = sum(r['safe_count'] for r in valid_results)
    overall_safety_rate = total_safe / total_samples if total_samples > 0 else 0
    
    print(f"\næ•´ä½“å¯è¾¾é›†å®‰å…¨æ€§:")
    print(f"  æ€»é‡‡æ ·ç‚¹: {total_samples}")
    print(f"  å®‰å…¨ç‚¹æ•°: {total_safe}")
    print(f"  å®‰å…¨ç‡: {overall_safety_rate*100:.1f}%")
    
    # 4.2 è½¨è¿¹åˆ†ç±»ç»Ÿè®¡
    goal_trajectories = [r for r in valid_results if r['goal_reached']]
    collision_trajectories = [r for r in valid_results if r['collision']]
    
    print(f"\næŒ‰è½¨è¿¹ç»“æœåˆ†ç±»:")
    print(f"  åˆ°è¾¾ç›®æ ‡çš„è½¨è¿¹: {len(goal_trajectories)}")
    if goal_trajectories:
        goal_safety = np.mean([r['safety_rate'] for r in goal_trajectories])
        print(f"    å¹³å‡å®‰å…¨ç‡: {goal_safety*100:.1f}%")
    
    print(f"  ç¢°æ’çš„è½¨è¿¹: {len(collision_trajectories)}")
    if collision_trajectories:
        collision_safety = np.mean([r['safety_rate'] for r in collision_trajectories])
        print(f"    å¹³å‡å®‰å…¨ç‡: {collision_safety*100:.1f}%")
    
    # 4.3 å¯è¾¾é›†å®½åº¦ç»Ÿè®¡
    all_widths_v = []
    all_widths_omega = []
    
    for result in valid_results:
        for r in result['results']:
            all_widths_v.append(r['width_v'])
            all_widths_omega.append(r['width_omega'])
    
    print(f"\nå¯è¾¾é›†å®½åº¦ç»Ÿè®¡:")
    print(f"  çº¿é€Ÿåº¦:")
    print(f"    å¹³å‡: {np.mean(all_widths_v):.6f}")
    print(f"    æ ‡å‡†å·®: {np.std(all_widths_v):.6f}")
    print(f"    æœ€å¤§: {np.max(all_widths_v):.6f}")
    
    print(f"  è§’é€Ÿåº¦:")
    print(f"    å¹³å‡: {np.mean(all_widths_omega):.6f}")
    print(f"    æ ‡å‡†å·®: {np.std(all_widths_omega):.6f}")
    print(f"    æœ€å¤§: {np.max(all_widths_omega):.6f}")
    
    # 4.4 æ€§èƒ½ç»Ÿè®¡
    print(f"\næ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    print(f"  å¹³å‡æ¯è½¨è¿¹: {elapsed_time/n_trajectories:.2f} ç§’")
    print(f"  å¹³å‡æ¯é‡‡æ ·ç‚¹: {elapsed_time/total_samples:.4f} ç§’")
    
    # ===== 5. ä¿å­˜ç»“æœ =====
    output_path = Path(__file__).parent.parent / "assets" / "reachability_results_batch.json"
    
    output_data = {
        'metadata': {
            'n_trajectories': n_trajectories,
            'total_samples': total_samples,
            'observation_error': 0.01,
            'sample_interval': 10,
            'elapsed_time': elapsed_time,
        },
        'summary': {
            'overall_safety_rate': overall_safety_rate,
            'total_safe': total_safe,
            'total_samples': total_samples,
            'goal_trajectories': len(goal_trajectories),
            'collision_trajectories': len(collision_trajectories),
        },
        'trajectories': all_results,
    }
    
    with open(output_path, 'w') as f:
        json.dump(output_data, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    print("="*70)
    print("\nğŸ‰ æ‰¹é‡éªŒè¯å®Œæˆï¼")


if __name__ == "__main__":
    main()